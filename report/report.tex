%% vi: set tabstop=2, set textwidth=80

\documentclass[11pt]{article}

\usepackage{homework}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{subfigure}
\usepackage{verbatim}
\usepackage[english]{babel}

% The report should be a description of your work during the lab sessions,
% focussing on the mean shift tracker. You should describe what you did, what you
% noticed and what you could have done different or could have improved. As you
% implemented the tracker you noticed different behaviour if you changed parts of
% the tracker, e.g. a different colour space or the number of bins in the
% histogram. Hopefully these insights have improved your tracker. This is why it
% is essential that you test the tracker also on a video of a domain other than
% soccer (or any other sport on a green field). This other domain will show how
% your implementation depends on the soccer domain. Observe how you can improve
% your design and them describe how you implemented this change or, for lack of
% time, describe how you would change your design. 

\title{Intelligent Multimedia Systems \\ Mean Shift Tracker and Color Models}

\author{F. Huizinga [0418862], B. Stoeller [0426857] \\
      \{folkerthuizinga,bramstoeller\}@gmail.com}

\date{December 27, 2009}

\begin{document}
\maketitle

\begin{abstract}
This report describes the implementation and results of a mean shift tracker
using the Epanechnikov kernel and various color space models. Furthermore, we
perform various analyses on the tracker and color models with the use of two
videos within different domains.
\end{abstract}


\section{Introduction} \label{sec:intro}
An object tracker consists of two major components, the \emph{Object Model} and
the \emph{Tracking Algorithm}. The object model is represented using a
histogram in some color space. The tracking algorithm is the Mean Shift
Algorithm~\cite{kernel-basedobject, real-timetracking}. This report compares
five different color spaces to represent the Object Model and their performance
is measured using two videos in different domains (sport and nature). The
report is organized as follows:  Section \ref{sec:implementation} describes the
implementation of the algorithm. The experiments and results are shown in
Section \ref{sec:results}. Section \ref{sec:conclusion} presents our
conclusions, and finally possible improvements are shown in Section
\ref{sec:future}.


\section{Implementation} \label{sec:implementation}
For our implementation we used the Matlab programming language. We describe the
implementation of the tracking algorithm and the object model separately.

\subsection{Object Model} \label{sec:model}
The object model is represented as a 2D or 3D histogram on the following color
spaces: $rgb$, $xyz$, $RGB$, $HSV$ and $XYZ$. We decided to use a fixed number
of total bins (i.e. the number of bins is not affected by the number of
dimensions).  More formally, if $N$ is the total number of bins, then the number
of bins $b$ for each dimension $i$ is $b_i = N^{1/d}$, where $d$ is the total
number of dimensions. 

\subsection{Tracking Algorithm} \label{sec:mst}
Algorithm \ref{alg:mst} shows our toplevel implementation of the mean shift
tracking algorithm, for the complete details we refer the reader to the
documented sourcecode\footnote{The sourcecode can be found at
http://github.com/Error323/ims}.

\begin{figure}
\centering
\subfigure[The sports domain, a soccer match.]{
\includegraphics[height=5.0cm]{img/soccer_orange_scene}
\label{fig:1a}
}
\subfigure[The nature domain, a hunting cheetah.]{
\includegraphics[height=5.0cm]{img/earth_cheetah_scene}
\label{fig:1b}
}
\caption{\ref{fig:1a} shows the sport domain where we track an orange soccer
player on the left. \ref{fig:1b} shows a scene from the movie Earth, where we
track the head of a cheetah chasing its prey.}
\label{fig:videos}
\end{figure}

\begin{algorithm}
	\caption{MeanShiftTracker($V$, $n$)}
	\begin{algorithmic}[1]
	\REQUIRE The video $V$ with $n$ frames
	\STATE $f_1 \leftarrow V[1]$ \COMMENT{Set the current frame}
	\STATE $\mathbf{y_0} \leftarrow \mathcal{S}(f_1)$ \COMMENT{Select target, store location}
	\STATE $\mathbf{q} \leftarrow \mathcal{M}(f_1, \mathbf{y_0})$ \COMMENT{Create the target model}
	\FOR{$i = 1$ to $n$}
		\STATE $f_i \leftarrow V[i]$
		\STATE $\mathbf{p_0} \leftarrow \mathcal{M}(f_i, \mathbf{y_0})$
		\STATE $bc_0 \leftarrow \mathcal{B}(\mathbf{p_0}, \mathbf{q})$ \COMMENT{Compute Bhattacharyya coefficient}
		\WHILE{true}
			\STATE $\mathbf{W} \leftarrow \mathcal{W}(f_i, \mathbf{y_0}, \mathbf{q}, \mathbf{p_0})$ \COMMENT{Compute the weights matrix}
			\STATE $\mathbf{y_1} \leftarrow \mathbf{y_0} + \mathcal{L}(\mathbf{W})$ \COMMENT{Compute the mean shift}
			\STATE $\mathbf{p_1} \leftarrow \mathcal{M}(f_i, \mathbf{y_1})$
			\STATE $bc_1 \leftarrow \mathcal{B}(\mathbf{p_1}, \mathbf{q})$
			\WHILE{$bc_1 < bc_0$} 
				\STATE $\mathbf{y_1} \leftarrow \frac{1}{2} \dot (\mathbf{y_0} + \mathbf{y_1})$ \COMMENT{Interpolate $\mathbf{y_1}$ if we shifted too far}
				\STATE $\mathbf{p_1} \leftarrow \mathcal{M}(f_i, \mathbf{y_1})$
				\STATE $bc_1 \leftarrow \mathcal{B}(\mathbf{p_1}, \mathbf{q})$
			\ENDWHILE
			\STATE $\mathbf{p_0} \leftarrow \mathbf{p_1}$
			\STATE $\mathbf{y_0} \leftarrow \mathbf{y_1}$
			\STATE $bc_0 \leftarrow bc_1$
			\IF{$\| \mathbf{y_1} - \mathbf{y_0} \| < \epsilon$}
				\STATE break \COMMENT{Break if locations are nearly equal}
			\ENDIF
		\ENDWHILE
	\ENDFOR
	\medskip
	\end{algorithmic}
\label{alg:mst}
\end{algorithm}

\newpage

\section{Experiments and Results} \label{sec:results}
For our experiments we applied the tracker to videos within two different
domains, nature and sports. Figure \ref{fig:videos} shows the tracker in action
on both domains. 
\begin{table}
\centering
\begin{tabular}{c|c|c}
$N$   & $N^{1/2}$ & $N^{1/3}$\\\hline\hline
$2^6$ & $2^3$     & $2^2$\\\hline
$3^6$ & $3^3$     & $3^2$\\\hline
$4^6$ & $4^3$     & $4^2$\\\hline
$5^6$ & $5^3$     & $5^2$\\
\end{tabular}
=
\begin{tabular}{r|r|r}
$N$     & $N^{1/2}$ & $N^{1/3}$\\\hline\hline
$64$    & $8$       & $4$\\\hline
$729$   & $27$      & $9$\\\hline
$4096$  & $64$      & $16$\\\hline
$15625$ & $125$     & $25$\\
\end{tabular}
\caption{Histogram sizes (i.e. number of bins).}
\label{table:bins}
\end{table}
In both videos a distinctive object was tracked using the various color models
and for each color model various histogram sizes, see Table \ref{table:bins}.

For a (somewhat) objective analysis of the various color models and various
histogram sizes, we chose to manually tag the target objects within the frame
sequences of each video. Figures \ref{fig:soccer} and \ref{fig:cheetah} show
our final results for the tracking of the orange soccer player and the
cheetah's head respectively.  Both figures show four graphs with the frame
number on the $x$-axis and the
euclidian distance, between the tracker's output and our labelled data, on the
$y$-axis. Each of the four graphs corresponds to a certain total number of
bins. From these results we can see that the $rgb$ model is the only model that
does not fail in all of the cases. This indicates that the $rgb$ color model is a
robust one and would indeed be our choice for object tracking.

\begin{table}
\centering
\begin{tabular}{r||r|r|r|r|r}
	      & $RGB$ & $rgb$ & $HSV$ & $XYZ$ & $xyz$ \\ \hline \hline
	   64 &  51.8 &   6.8 &   8.1 & 114.2 &  81.3 \\ \hline
	  729 &  57.9 &   5.7 &   5.7 &  45.8 &  66.5 \\ \hline
	 4096 &  31.5 &   4.8 &  56.8 &  58.4 &   5.5 \\ \hline
	15625	&  44.8 &   4.4 &   4.5 &  57.9 &   4.1 \\ \hline
\end{tabular}
\caption{Mean Euclidean error derived from 201 frames from the soccer domain and
300 frames from the nature domain. Note that using normalized $rgb$ results in
the highest accuracy.}
\label{table:error}
\end{table}

\begin{figure}
\centering
\subfigure[$64$ bins]{
\includegraphics[height=6.0cm]{img/soccer_orange_64}
\label{fig:3a}
}
\subfigure[$729$ bins]{
\includegraphics[height=6.0cm]{img/soccer_orange_729}
\label{fig:3b}
}
\\
\subfigure[$4096$ bins]{
\includegraphics[height=6.0cm]{img/soccer_orange_4096}
\label{fig:3c}
}
\subfigure[$15625$ bins]{
\includegraphics[height=6.0cm]{img/soccer_orange_15625}
\label{fig:3d}
}
\caption{Each graph shows the performance of the five different color models
for a number of bins on the soccer movie when tracking the orange player. All
four graphs show a very distinctive pattern on the color models that lost
track. This is the result of occlusion caused by a white player. The white
player walks in front of the orange player (the target) and pushes the model
away at which point it finds a new orange player and starts tracking him.}
\label{fig:soccer}
\end{figure}

\begin{figure}
\centering
\subfigure[$64$ bins]{
\includegraphics[height=6.0cm]{img/earth_cheetah_64}
\label{fig:2a}
}
\subfigure[$729$ bins]{
\includegraphics[height=6.0cm]{img/earth_cheetah_729}
\label{fig:2b}
}
\\
\subfigure[$4096$ bins]{
\includegraphics[height=6.0cm]{img/earth_cheetah_4096}
\label{fig:2c}
}
\subfigure[$15625$ bins]{
\includegraphics[height=6.0cm]{img/earth_cheetah_15625}
\label{fig:2d}
}
\caption{Each graph shows the performance of the five different color models for
a number of bins on the cheetah movie when tracking the cheetah's head.
\ref{fig:2a} shows that several color models have completely lost track,
indicating that $64$ is not enough. In \ref{fig:2b} only the $xyz$ model failed.
In both \ref{fig:2c} and \ref{fig:2d} all color models show good performance.
This indicates that the more bins used, the better the model becomes.}
\label{fig:cheetah}
\end{figure}

\section{Conclusions} \label{sec:conclusion}
This report introduced an implementation of the mean shift tracking algorithm
together with various color models applied to videos from two different domains.
From the results we conclude that a significant histogram size should be chosen
to represent a model for robust tracking. An insufficient amount of bins
overgeneralizes the model, at which point the tracker loses its target object as
both the target and background are (according to the model) indistinguishable.
Furthermore, the best color model, according to our results, is the normalized
$rgb$ model. That is, the $rgb$ color model had the best overall performance
across the domains and various histogram sizes.

\section{Future Work} \label{sec:future}
A lot can be improved in the current implementation. Some of these improvements
are:
\paragraph{Scale} The current implementation is not scale invariant. This
results in tracking problems when an object is getting closer or further away
from the camera or when a camera zooms in or out. In these cases the target
model gets outdated and the eventually the tracker will fail. Implementing
scale invariance will solve this problem. This can be done by ``Compute the
Epanechnikov kernel for various scales and select the best scale for each
frame using the Bhattacharyya distance'' [TODO: rewrite and explain]

\paragraph{Kalman} When occlusion or abrupt [TODO: better description] camera
motion occure the tracker tends to jitter a lot and in some cases it might lose
the target object. By applying a Kalman filter an assumption about the expected
motion (i.e. the expected location of the target object in the next frame) is made
and therefore the tracker would become much more stable.

\paragraph{Color} The tracker asumes a color model has been chosen by the user /
engeneer. We suspect that the best choice for a color model depends on the scene
or the domain. It might be a good idea to implement some automated analysis to
determine which color space is best suited for the target model for every
induividual scene. For example the color space model with the highest variance
could be chosen or the color model in which the target object differs most from
the rest of the scene.

\paragraph{Spatial layout} To improve the target model (especially when complex
target objects have to be tracked) one could divide the kernel into several
tiles [TODO: cite ``adjacent-line-segments-paper'' ?] to store some information
about the spatial layout of the target object to create more discriminative
models. One should use caution with respect to the problem of overfitting.

\renewcommand\bibname{References}
\bibliography{references}
\bibliographystyle{IEEEtran}
\end{document}
